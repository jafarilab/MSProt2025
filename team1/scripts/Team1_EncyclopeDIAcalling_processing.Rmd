---
title: "Capstone project - SOX9-dependent fibrosis, proteomics analysis"
output:
  pdf_document: default
  html_notebook: default
---

Libraries

```{r}

# Make distinction between CRAN and Bioconductor packages
install.packages("BiocManager", 
                 "dplyr", 
                 "stringr", 
                 "RSQLite", 
                 "DBI", 
                 "tidyverse",
                 "ggpubr")

BiocManager::install(c('rpx', 
                       'mzR', 
                       'MSnbase',
                       'PSMatch', 
                       'msdata',
                       'QFeatures', 
                       'msqrob2'))
```

```{r}
library(rpx) # Bioconductor
library(mzR) # Bioconductor
library(MSnbase) # Bioconductor
library(dplyr) # CRAN
library(PSMatch) # Bioconductor
library(msdata) # Bioconductor
library(readr) # CRAN
library(stringr) # CRAN
library(RSQLite) # CRAN
library(DBI) # CRAN
library(QFeatures) # Bioconductor
library(tidyverse) # CRAN
library(ggpubr) # CRAN
library(msqrob2) # Bioconductor
library(factoextra)
```

For reviewers (re-running the analysis):

1)  Open this project folder as the working directory.

2)  Place any external inputs in this working directory (e.g., files from Zenodo).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Retrieve mzML files from PRIDE

```{r}
px <- PXDataset("PXD061542")
px_files <- grep('*.mzML', pxfiles(px))

mzmlFiles <- pxget(px, pxfiles(px))

```

To convert the .mzML files containing the raw data to .mzID files with the peptide/protein identification results, we used the external tool searchgui () (parameters (?)). To facilitate the downstream analysis in R, we converted the mzID files to .csv files (using a separate Python script). Here, I'm trying to achieve a similar result calling EncyclopeDIA (an alternative tool to identify peptide/proteins from the raw data). EncyclopeDIA was the tool used in the original paper.

PPlease get the excutable from <https://bitbucket.org/searleb/encyclopedia/downloads/> and put it in the current project folder.

Invoking EncyclopeDIA via R

```{r}
Sys.setenv(JAVA_HOME = "/opt/homebrew/opt/openjdk/libexec/openjdk.jdk/Contents/Home/") # for R to be able to locate JAVA, which is needed to execute EncyclopeDIA 
```

```{r}
encyclopeDIA_jar <- "./encyclopedia-4.7.11-executable.jar" # define path to the EncyclopeDIA executable 

# Mus musculus prosit-generated dlib to use as scaffold for DIA analysis. From Scaffold (https://support.proteomesoftware.com/hc/en-us/articles/360035151172-Prosit-Derived-Spectral-Libraries-for-Scaffold-DIA-Searches#h_01FE1R4118YYKAG5WRHYFCG767). 
# The library predicts DIA-specific libraries from all possible +2H and +3H peptides in the FASTA database, and reportedly they perform as well as libraries generated by DDA library-generating experiments. 
libraryFile <- "./mus_musculus_prosit_generated_library.dlib"

# Use the M. musculus fasta file provided by Scaffold (https://support.proteomesoftware.com/hc/en-us/articles/360035151172-Prosit-Derived-Spectral-Libraries-for-Scaffold-DIA-Searches#h_01FE1R4118YYKAG5WRHYFCG767)
# with the library file 
ref <- "./mus_musculus_reviewed_uniprot.fasta"

# Specify output directory 
output_dir <- "~/results/encyclopeDIA_out2"
#output2_dir <- "~/Desktop/Proteomics/CapstoneProjectTeam1/data/results/encyclopeDIA_out/quant"

# Construct command to run EncyclopeDIA within R - this generates a Chromatogram Library in ELIB format. The tool also uses the M. musculus reference proteome as a search background.

## Uncomment to run, takes ~2 h per file 
# for (mzml in mzmlFiles){
#   outFile <- file.path(output_dir, paste0(basename(tools::file_path_sans_ext(mzml))))
# 
#   cmd <- paste("java -Xmx20G -jar", encyclopeDIA_jar,
#              "-l", libraryFile,
#              "-i", mzml,
#              "-f", ref)
#   cat("Running:", mzml, "\n")
#   # Run
#   #system(cmd)
# } 
## This outputs several files, among which are graphs that serve as QC. This only identifies peptides / proteins but does not provide quantification results that can be used to comparae between samples (since it is a DIA experiment, the quantification engine chooses the best ions from each sample for quantification and it does not make sense to do it per sample because the best ion might differ from sample to sample)

```

To run Encyclopedia to generate global quantitative results

```{r}
## Uncoment to run 
# cmd <- paste("java -Xmx12G -jar", encyclopeDIA_jar,
#              "-l", libraryFile,
#              "-i", "~/encyclopeDIA_out/",
#              "-f", ref,
#              "-libexport",
#              "-a true",
#              "-o ~/encyclopeDIA_out/output.elib")
#   
# 
#   #cat("Running:", mzml,"\n")
#   # Run
# system(cmd)
```

Glimpse at the features file, which contains the raw match-level data between the spectra and library peptides. These are the ones we use to create the PSM object

```{r}
feat <- read.table("~/encyclopeDIA_out/bde162c4da2_Tsiokas_111622_Sample_17_Clone7_expt2.mzML.features.txt", header = T)

output_concatenated <- read.table("~/encyclopeDIA_out/output_concatenated_features.txt", header = T)

colnames(output_concatenated) 
```

Glimpse at the output elib files

```{r}
elibFile <- "~/encyclopeDIA_out/bde162c4da2_Tsiokas_111622_Sample_17_Clone7_expt2.mzML.elib"

#con <- dbConnect(RSQLite::SQLite(), elibFile)

#dbListTables(con)
```

```{r}
precursors <- dbReadTable(con, "peptidescores")

# View columns
str(precursors)
head(precursors)
```

Create PSM object from EncyclopeDIA .tsv files:

```{r}
# list feature files
#data/results/encyclopeDIA_out
targetFiles_fromEncyclopeDIA <- list.files("~/encyclopeDIA_out/", pattern = "*features.txt$", full.names = T)
# decoyFiles_fromEncyclopeDIA <- list.files("data/results/encyclopeDIA_out/", pattern = "*encyclopedia.decoy.txt", full.names = T)

#df <- read_table("data/results/encyclopeDIA_out/bde162c4da2_Tsiokas_111622_Sample_17_Clone7_expt2.mzML.encyclopedia.txt")
# Do not take the output file that contains the integated analysis
targetFiles_fromEncyclopeDIA <- targetFiles_fromEncyclopeDIA[grep("output", targetFiles_fromEncyclopeDIA, invert = T)]

# First, we combined all files into 1 data frame
all_feat <- lapply(targetFiles_fromEncyclopeDIA, function(f){
  df <- read_table(f)
  source_file <- basename(f)
  df$sample <- gsub("\\..*", "", source_file) # to keep track of the different samples
  # Add groups (WT vs KO) 
  df <- df %>% 
    mutate(group = case_when(
    str_detect(string = sample, pattern = "EV") ~ "WT",
    str_detect(string = sample, pattern = "Parental") ~ "WT",
    TRUE ~ "KO"
  ))
  return(df)
}) %>% bind_rows()

colnames(all_feat)
# all_decoy <- lapply(decoyFiles_fromEncyclopeDIA, function(f){
#   df <- readr::read_table(f)
#   source_file <- basename(f)
#   df$sample <- gsub("\\..*", "", source_file) 
#   # Add groups
#   df <- df %>% 
#     mutate(group = case_when(
#     str_detect(string = sample, pattern = "EV") ~ "WT",
#     str_detect(string = sample, pattern = "Parental") ~ "WT",
#     TRUE ~ "KO"
#   ))
#   return(df)
# }) %>% bind_rows()

# head(all_decoy)
# 
# all_feat$isDecoy <- "NO"
# all_decoy$isDecoy <- "YES"

# Combine 
#combined_df <- bind_rows(all_feat, all_decoy)

#table(combined_df$isDecoy)

# Clean the df
psm_data <- all_feat %>%
  #mutate(charge = pmax(charge1, charge2, charge3, charge4, na.rm = TRUE),
    #score = ifelse(is.na(HyperScore), xCorrLib, HyperScore)) %>%
   mutate(score = HyperScore, 
          charge = case_when(
            charge1 != 0 ~ 1, 
            charge2 != 0 ~ 2, 
            charge3 != 0 ~ 3, 
            TRUE ~ 4
          )) %>%
  filter(isIntegratedSignal == TRUE) %>% # keep only the rows from which encyclopeDIA could extract a signal
  # keep columns of interest
  dplyr::select(
    ScanNr,
    sequence,
    charge,
    score,
    precursorMz,
    rt = RTinMin,
    deltaRt = deltaRT,
    ms2Error = ms2MassError,
    score,
    protein = Proteins,
    sample,
    group
  ) %>% 
  rename(
    "spectrumID" = ScanNr,
    "accession" = protein, 
  ) %>% 
  mutate(isDecoy = case_when(
    str_detect(string = accession, pattern = "DECOY") ~ "TRUE", 
    TRUE ~ "FALSE"
  )) %>% 
  mutate(isDecoy = as.logical(isDecoy))

table(psm_data$isDecoy)
```

Plot score distribution before rank filtering

```{r}
ggplot(psm_data, aes(x = score, fill = isDecoy))  +  
  scale_fill_manual(values = c("lightgray","#F59CA9")) +
  geom_histogram(alpha = 0.8) + 
  #scale_fill_manual(values = c("darkgreen")) +
  labs(title = "Score distribution by SpectrumID", x = "Score", y = "Density") + 
  theme_minimal() + 
  theme(aspect.ratio  = 1)
```

Manually add rank

```{r}
psm_data_ranked <- psm_data %>%
  mutate(group = spectrumID) %>%
  group_by(group) %>%
  arrange(desc(score), .by_group = TRUE) %>%
  mutate(rank = row_number()) %>%
  ungroup()%>% 
  filter(rank == 1) # i.e. keep best scoring peptide match 
```

Remove multi-matching spectra (if present)

```{r}
mltm <- psm_data_ranked %>%
  group_by(spectrumID) %>% 
  tally() %>%
  filter(n > 1) %>%
  pull(spectrumID)

cat("There are no multi-matching spectra")
```

Score distribution after rank - filtering

```{r}
ggplot(psm_data_ranked, aes(x = score, fill = isDecoy))  + 
  scale_fill_manual(values = c("lightgray","#F59CA9")) +
  geom_histogram(alpha = 0.8) + 
  #scale_fill_manual(values = c("darkgreen")) +
  labs(title = "Score distribution by SpectrumID", x = "Score", y = "Density") + 
  theme_minimal() + 
  theme(aspect.ratio  = 1)
```

Create the PSM object

```{r}
psm_obj <- PSMatch::PSM(x = psm_data_ranked, 
                        spectrum = "spectrumID", peptide = "sequence",
           protein = "accession", decoy = "isDecoy", rank = "rank", score = "score")

psm_obj
names(psm_obj)
```

N of decoy hits

```{r}
table(psm_obj$isDecoy)
# 
# cat("Decoy hits:", n_decoy, "\nTarget hits:", n_target)
```

```{r}
psm_obj@metadata

filt_psm = psm_obj %>% 
  filterPsmRank() %>% 
  filterPsmDecoy()

length(filt_psm$spectrumID)
```

```{r}
# Total PSMs
n_total <- length(psm_obj$spectrumID)

# Target vs Decoy
is_decoy <- grepl("^DECOY", psm_obj$accession)  # adjust prefix if needed
n_decoy <- sum(is_decoy)
n_target <- n_total - n_decoy

# Unique peptides (sequence + charge)
peptide_df <- data.frame(
  peptide = filt_psm$sequence,
  charge = filt_psm$charge
) 
n_unique_peptides <- n_distinct(paste(peptide_df$peptide, peptide_df$charge, sep = "_"))

# Unique proteins
n_unique_proteins <- n_distinct(filt_psm$accession)

# Score summary
score_summary <- summary(filt_psm$score)

```

```{r}
cat("PSM Object Summary\n")
cat("--------------------------\n")
cat("Total PSMs:         ", n_total, "\n")
cat("Target PSMs:        ", n_target, "\n")
cat("Decoy PSMs:         ", n_decoy, "\n")
cat("Unique Peptides:    ", n_unique_peptides, "\n")
cat("Unique Proteins:    ", n_unique_proteins, "\n\n")

cat("Score Summary:\n")
print(score_summary)


```

Adjacency matrix

```{r}
adj <- makeAdjacencyMatrix(filt_psm, binary = F)

dim(adj)

adj[1:5, 1:5]
```

Explore connected components

```{r}
cc <- ConnectedComponents(adj)
length(cc)
cc
connectedComponents(cc, 4)
```

There are no protein groups identified by a single peptide 8474 are single proteins identified by multiple unique peptides

Protein groups (proteins that share the same peptide matches)

```{r}
psm_data_ranked <- psm_data_ranked %>%
  ungroup() %>% 
  mutate(ProteinsList = str_split(accession, ";"),
         GroupKey     = sapply(ProteinsList, function(v) paste(sort(v), collapse=";")))

# How many PSMs with more than one protein 
multiProt <- grep(";", psm_data_ranked$accession)

cat("There are", length(multiProt), "protein groups in the data set")

#psm_filter$ProteinsList
```

Razor protein (the best supported by unique peptides)

```{r}
pep2prot <- psm_data_ranked %>%
  select(sequence, ProteinsList) %>%
  tidyr::unnest(ProteinsList) %>%
  distinct()

# Count how many unique peptides for each protein
pep_counts <- pep2prot %>%
  group_by(sequence) %>%
  filter(n()==1) %>%           # keep only uniqueâ€mapping peptides
  ungroup() %>%
  dplyr::count(ProteinsList, name="n_unique_peptides") %>% 
  as.data.frame()

razor_map <- pep_counts %>%
  inner_join(psm_data_ranked %>% select(GroupKey, ProteinsList) %>% distinct() %>% mutate(ProteinsList = as.character(ProteinsList)),
             by="ProteinsList") %>%
  group_by(GroupKey) %>%
  filter(n_unique_peptides == max(n_unique_peptides)) %>% # keep the row with more petides 
  slice(1) %>%  # in ties, just take the first
  ungroup() %>%
  select(GroupKey, RazorProtein=ProteinsList)

# Merge back to psm object
psm_data_ranked = psm_data_ranked %>% 
  left_join(razor_map, by ="GroupKey")

cat("Unique razor proteins:", length(unique(psm_data_ranked$RazorProtein)), "\n")
```

Peptide-level data processing, protein aggregation and DEA

Retrieve files exported from output.elib

```{r}
quant <- read_csv("./peptidequants.csv")
pep_to_prot <- read_csv("./peptidetoprotein.csv")

# Filter out decoys keps in these files
pep_to_prot <- pep_to_prot %>% 
  filter(isDecoy == 0)

table(quant$SourceFile)



# To check that all peptides identified in every sample
quant %>% 
  group_by(PeptideSeq) %>% 
  summarise(ndistfiles = n_distinct(SourceFile)) -> df

table(df$ndistfiles)
```

```{r}
# proteins
nest_prot <- pep_to_prot %>% 
  group_by(PeptideSeq) %>% 
  mutate(Proteins = paste0(ProteinAccession, collapse = ";")) %>% 
  select(-c("isDecoy", "ProteinAccession"))

# merge with peptide to protein 
quant_prot <- inner_join(quant, nest_prot, by = "PeptideSeq") %>% 
  filter(!is.na(Proteins))

table(quant_prot %>% duplicated())

# pivot wider
quant_wide <- quant_prot %>% 
  unique() %>% 
  pivot_wider(id_cols = c(PeptideSeq, Proteins), names_from = SourceFile, values_from = TotalIntensity)

head(quant_wide)

psm_se <- readQFeatures(quant_wide,
                        quantCols = colnames(quant_wide)[3:12],
                        fnames = "PeptideSeq", 
                        name = "peptides")


psm_se <- QFeatures::zeroIsNA(psm_se, i = "peptides") # zeroes sho
nna = nNA(psm_se, 1)
```

```{r}
#rm(psm_se_filtered)
psm_se_filtered = filterNA(psm_se, 0.2, i=1) # kept every peptide with less than 20% missing data

nna = nNA(psm_se_filtered, 1)
nna
```

```{r, warning=FALSE}
## Norm
# First impute missing data
psm_se_filtered <- QFeatures::impute(psm_se_filtered, method = "knn", i = "peptides", name = "imputed_peptides")

# log2 transform
psm_se_filtered <- logTransform(psm_se_filtered, base = 2, i = "imputed_peptides", name = "log_peptides")


assay(psm_se_filtered, i = "log_peptides") %>% 
  as.data.frame() %>% 
  pivot_longer(cols = everything(), names_to = "File", values_to = "Intensity") -> t_psm

ggplot(t_psm, aes(x = as.factor(File), y = Intensity, fill = "File")) + 
  scale_fill_manual(values = "#C0E0DE") + 
  geom_boxplot(outliers = T) + 
  theme_minimal() + 
  theme(aspect.ratio = 1,
        axis.text.x = element_blank(),
        legend.position ="none") + 
  xlab("") -> g_before
limma::plotDensities(assay(psm_se_filtered[["log_peptides"]]))

# Check different norm methods 
psm_se_filtered <- QFeatures::normalize(psm_se_filtered, method = "center.median", i = "log_peptides", name = "norm_center_median_log")
psm_se_filtered <- QFeatures::normalize(psm_se_filtered, method = "center.mean", i = "log_peptides", name = "norm_center_mean_log")

psm_se_filtered <- QFeatures::normalize(psm_se_filtered, method = "vsn", i = "peptides", name = "norm_vsn")

assay(psm_se_filtered, i = "norm_center_median_log") %>% 
  as.data.frame() %>% 
  pivot_longer(cols = everything(), names_to = "File", values_to = "Intensity") -> t_psm_median

assay(psm_se_filtered, i = "norm_center_mean_log") %>% 
  as.data.frame() %>% 
  pivot_longer(cols = everything(), names_to = "File", values_to = "Intensity") -> t_psm_mean

assay(psm_se_filtered, i = "norm_vsn") %>% 
  as.data.frame() %>% 
  pivot_longer(cols = everything(), names_to = "File", values_to = "Intensity") -> t_psm_vsn

ggplot(t_psm_median, aes(x = as.factor(File), y = Intensity, fill = "File")) + 
  scale_fill_manual(values = "#C0E0DE") + 
  geom_boxplot(outliers = T) + 
  theme_minimal() + 
  theme(aspect.ratio = 1,
        axis.text.x = element_blank(),
        legend.position ="none") + 
  xlab("") -> g_median

ggplot(t_psm_mean, aes(x = as.factor(File), y = Intensity, fill = "File")) + 
  scale_fill_manual(values = "#C0E0DE") + 
  geom_boxplot(outliers = T) + 
  theme_minimal() + 
  theme(aspect.ratio = 1,
        axis.text.x = element_blank(),
        legend.position ="none") + 
  xlab("")-> g_mean

ggplot(t_psm_vsn, aes(x = as.factor(File), y = Intensity, fill = "File")) + 
  scale_fill_manual(values = "#C0E0DE") + 
  geom_boxplot(outliers = T) + 
  theme_minimal() + 
  theme(aspect.ratio = 1,
        axis.text.x = element_blank(),
        legend.position = element_blank()) + 
  xlab("") -> g_vsn

#pdf("../../../../CapstoneProjectTeam1/norm_plots.pdf", height = 4, width = 10)
ggarrange(g_before, g_mean , g_median, ncol = 3) # keep median
#dev.off()

# Protein aggrgation on normalised peptides 
qf_prot <- aggregateFeatures(
  object = psm_se_filtered,
  i     = "norm_center_median_log",     # aggregate the peptide assay
  fcol  = "Proteins",    
  name  = "proteins",     # name for the new protein-level assay
  fun   = MsCoreUtils::robustSummary
)

limma::plotDensities(assay(qf_prot[["peptides"]]), legen =F)

```

```{r}
head(assay(qf_prot[["proteins"]]))
```

```{r}
# extract protein matrix
prot_mat <- assay(qf_prot, "proteins")  
head(prot_mat)
```

Generate a condition table for each sample

```{r}
samples <- colnames(assay(qf_prot))

conditions <- data.frame(c(samples), "")

colnames(conditions) <- c("SourceFile", "condition")
 
conditions <- conditions %>% 
  mutate(condition = case_when(
    str_detect(string = samples, pattern = "EV") ~ "WT",
    str_detect(string = samples, pattern = "Parental") ~ "WT",
    TRUE ~ "KO"
  )) %>% 
  column_to_rownames(var ="SourceFile")

table(conditions)
```

```{r}
colData(qf_prot) <- conditions
```

DE analysis

```{r}
#pdf("norm_center_median_log_densities.pdf", height = 5, width = 5)
limma::plotDensities(assay(qf_prot[["norm_center_median_log"]]), legend = F)
#dev.off()
```

Plot multidimensional summary

```{r}
colors <- case_when(
    str_detect(string = rownames(conditions), pattern = "EV") ~ "black",
    str_detect(string = rownames(conditions), pattern = "Parental") ~ "gray",
    TRUE ~ "red"
  )

#pdf("mds_pep.pdf", height = 6, width = 6)
limma::plotMDS(assay(qf_prot[["norm_center_median_log"]]), col=colors)
#dev.off()
```

Plot PCA results

```{r}
pca_prot <-
    qf_prot[["proteins"]] %>%
    filterNA() %>%
    assay() %>%
    t() %>%
    prcomp(scale = TRUE, center = TRUE) %>%
    fviz_pca_ind(habillage = qf_prot$condition,
                 title = "Proteins (robustSummary aggregation)",palette = c("#8DDCA4", "#413C58"))

#pdf("pca_proteins.pdf", height = 6, width = 6)
pca_prot
#dev.off()
```

```{r}
#pdf("mds_prot.pdf", height = 6, width = 6)
limma::plotMDS(assay(qf_prot[["proteins"]]), col = colors)
#dev.off()
```

```{r, warning=FALSE}
qf_prot <- msqrob(object = qf_prot, i = "proteins", formula = ~condition, overwrite =T)
```

```{r}
getCoef(rowData(qf_prot[["proteins"]])$msqrobModels[[1]])


# Create contrasts
L <- makeContrast("conditionWT=0", parameterNames = c("conditionWT"))

qf_prot <- msqrob2::hypothesisTest(object = qf_prot, i = "proteins", contrast = L, overwrite =T)
```

Create volcano plot

```{r}
volcano <- ggplot(
    rowData(qf_prot[["proteins"]])$conditionWT,
    aes(x = logFC, y = -log10(pval), color = adjPval < 0.05)
) +
    geom_point(cex = 2.5) +
    scale_color_manual(values = alpha(c("black", "red"), 0.5)) +
    theme_minimal() + 
    theme(aspect.ratio = 1)

pdf("vp_WTvsKO.pdf", height = 5, width = 5)
volcano
dev.off()
```

Try to locate TMEM237 (<https://www.uniprot.org/uniprotkb/Q3V0J1/entry>)

```{r}
res_df <- rowData(qf_prot[["proteins"]])$conditionWT

res_df

#rownames(res_df)

grep("*Q3V0J1*", rownames(res_df)) -> check

res_df[check,]
```

```{r, fig.height=12}
sigNames <- rowData(qf_prot[["proteins"]])$conditionWT %>%
    rownames_to_column("proteins") %>%
    filter(adjPval < 0.05) %>%
    pull(proteins)

#pdf("heatmap.pdf", width = 9, height = 6)
heatmap(assay(qf_prot[["proteins"]])[sigNames, ])
#dev.off()
```

Get results table from PRIDE

```{r}
# Download mztab file 
mzTabFiles <- pxget(px, grep("mztab", pxfiles(px)))

res <- readMzTabData(mzTabFiles, version = '0.9')
res@featureData # 4923 proteins
```
